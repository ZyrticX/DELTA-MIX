"""
Daily Update System - ×¢×“×›×•×Ÿ ×™×•××™ ××•×˜×•××˜×™ ×©×œ × ×ª×•× ×™× ×•×§×•×¨×œ×¦×™×•×ª
"""

import os
import sys
import pandas as pd
from datetime import datetime, timedelta
from typing import List, Dict, Any
import logging
import pickle

# ×”×•×¡×¤×ª × ×ª×™×‘ ×œ××•×“×•×œ×™×
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from data_fetcher import DataFetcher
from .config import COMPUTATION_PARAMS, PATHS, CACHE_CONFIG
from .db_client import SupabaseClient
from .pre_compute import PreComputeEngine
from .utils import calculate_correlation_for_date, calculate_future_return, classify_movement

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class DailyUpdateEngine:
    """
    ×× ×•×¢ ×¢×“×›×•×Ÿ ×™×•××™
    """
    
    def __init__(self):
        """××ª×—×•×œ"""
        self.data_fetcher = DataFetcher(cache_dir=PATHS['data_cache'])
        self.db_client = SupabaseClient()
        self.pre_compute = PreComputeEngine()
        self.params = COMPUTATION_PARAMS
    
    def update_stock_data(self, symbols: List[str]) -> Dict[str, Any]:
        """
        ×¢×“×›×•×Ÿ × ×ª×•× ×™ ×× ×™×•×ª ×œ×™×•× ×”××—×¨×•×Ÿ
        
        Args:
            symbols: ×¨×©×™××ª ×× ×™×•×ª ×œ×¢×“×›×•×Ÿ
            
        Returns:
            Dict ×¢× ×¡×˜×˜×™×¡×˜×™×§×•×ª
        """
        logger.info(f"ğŸ“¥ ××¢×“×›×Ÿ × ×ª×•× ×™× ×¢×‘×•×¨ {len(symbols)} ×× ×™×•×ª...")
        
        updated = 0
        failed = []
        
        # ×ª××¨×™×›×™×
        end_date = datetime.now().strftime("%Y-%m-%d")
        start_date = (datetime.now() - timedelta(days=5)).strftime("%Y-%m-%d")  # 5 ×™××™× ××—×•×¨×” (×œ××§×¨×” ×©×™×© gaps)
        
        for symbol in symbols:
            try:
                # ×”×•×¨×“×ª × ×ª×•× ×™× (×¢× force_download=False ×›×“×™ ×œ×”×©×ª××© ×‘×§××© ×× ××¤×©×¨)
                df = self.data_fetcher.download_stock_data(
                    symbol,
                    start_date=start_date,
                    end_date=end_date,
                    use_cache=True,
                    force_download=False  # ×œ× ×›×•×¤×” ×”×•×¨×“×” - ××©×ª××© ×‘×§××© ×× ×§×™×™× ×•×¢×“×›× ×™
                )
                
                if df is not None and not df.empty:
                    # ×‘×“×™×§×” ×× ×™×© × ×ª×•× ×™× ×—×“×©×™×
                    cache_file = os.path.join(PATHS['data_cache'], f"{symbol}_{start_date}_{end_date}.pkl")
                    
                    if os.path.exists(cache_file):
                        # ×˜×¢×™× ×ª ×§××© ×™×©×Ÿ
                        with open(cache_file, 'rb') as f:
                            old_df = pickle.load(f)
                        
                        # ×”×©×•×•××”
                        if len(df) > len(old_df):
                            updated += 1
                            logger.debug(f"âœ… {symbol}: ×¢×•×“×›×Ÿ ({len(old_df)} â†’ {len(df)} ×©×•×¨×•×ª)")
                        else:
                            logger.debug(f"â„¹ï¸ {symbol}: ××™×Ÿ ×¢×“×›×•× ×™×")
                    else:
                        updated += 1
                        logger.debug(f"âœ… {symbol}: × ×•×¦×¨ ×§××© ×—×“×©")
                else:
                    failed.append(symbol)
                    
            except Exception as e:
                logger.warning(f"âš ï¸ ×©×’×™××” ×‘×¢×“×›×•×Ÿ {symbol}: {e}")
                failed.append(symbol)
        
        logger.info(f"âœ… ×¢×“×›×•×Ÿ ×”×•×©×œ×: {updated} ×¢×•×“×›× ×•, {len(failed)} × ×›×©×œ×•")
        
        return {
            'updated': updated,
            'failed': failed,
            'total': len(symbols)
        }
    
    def compute_today_snapshots(self) -> int:
        """
        ×—×™×©×•×‘ snapshots ×œ×™×•× ×”××—×¨×•×Ÿ ×‘×œ×‘×“
        
        Returns:
            ××¡×¤×¨ snapshots ×©× ×•×¦×¨×•
        """
        logger.info("ğŸ“Š ××—×©×‘ snapshots ×œ×™×•× ×”××—×¨×•×Ÿ...")
        
        # ×§×‘×œ×ª ×¨×©×™××ª ×× ×™×•×ª
        stocks_from_db = self.db_client.get_stock_list(active_only=True)
        if not stocks_from_db:
            logger.error("âŒ ×œ× × ××¦××• ×× ×™×•×ª ×‘-DB!")
            return 0
        
        symbols = [s['symbol'] for s in stocks_from_db]
        
        # ×˜×¢×™× ×ª × ×ª×•× ×™×
        try:
            stock_data = self.pre_compute.load_stock_data(symbols)
        except Exception as e:
            logger.error(f"âŒ ×©×’×™××” ×‘×˜×¢×™× ×ª × ×ª×•× ×™×: {e}")
            return 0
        
        # ×ª××¨×™×š ×”×™×•×
        today = datetime.now().date()
        today_datetime = pd.to_datetime(today)
        
        # ×‘×“×™×§×” ×©×™×© ××¡×¤×™×§ × ×ª×•× ×™×
        if today_datetime not in stock_data.index:
            logger.warning("âš ï¸ ××™×Ÿ × ×ª×•× ×™× ×œ×™×•× ×”× ×•×›×—×™, ××©×ª××© ×‘×™×•× ×”××—×¨×•×Ÿ...")
            today_datetime = stock_data.index[-1]
        
        # ×‘×“×™×§×” ×©×™×© lookback_days × ×ª×•× ×™×
        lookback_days = self.params['lookback_days']
        date_idx = stock_data.index.get_indexer([today_datetime], method='nearest')[0]
        
        if date_idx < lookback_days - 1:
            logger.error(f"âŒ ××™×Ÿ ××¡×¤×™×§ × ×ª×•× ×™× (×¦×¨×™×š {lookback_days} ×™××™×)")
            return 0
        
        # ×—×™×©×•×‘ snapshots
        dates = [today_datetime]
        snapshots = []
        
        for stock in symbols:
            try:
                stock_snapshots = self.pre_compute.compute_snapshots_for_stock(
                    stock_data, stock, dates, symbols,
                    lookback_days,
                    self.params['forward_days'],
                    self.params['correlation_threshold']
                )
                snapshots.extend(stock_snapshots)
            except Exception as e:
                logger.warning(f"âš ï¸ ×©×’×™××” ×‘×—×™×©×•×‘ snapshot ×¢×‘×•×¨ {stock}: {e}")
                continue
        
        # ×©××™×¨×” ×œ-DB
        if snapshots:
            logger.info(f"ğŸ’¾ ×©×•××¨ {len(snapshots)} snapshots ×œ-DB...")
            self.db_client.insert_correlation_snapshots(snapshots)
        
        logger.info(f"âœ… × ×•×¦×¨×• {len(snapshots)} snapshots")
        
        return len(snapshots)
    
    def update_pattern_statistics(self):
        """
        ×¢×“×›×•×Ÿ pattern statistics
        """
        logger.info("ğŸ“ˆ ××¢×“×›×Ÿ pattern statistics...")
        
        # ×§×‘×œ×ª ×¨×©×™××ª ×× ×™×•×ª
        stocks_from_db = self.db_client.get_stock_list(active_only=True)
        if not stocks_from_db:
            return
        
        symbols = [s['symbol'] for s in stocks_from_db]
        
        # TODO: ×™×™×©×•× ×—×™×©×•×‘ pattern statistics
        # ×–×” ×“×•×¨×© ××’×¨×’×¦×™×” ×©×œ snapshots ×œ×¤×™ pattern signature
        logger.info("âš ï¸ ×¢×“×›×•×Ÿ pattern statistics ×¢×“×™×™×Ÿ ×œ× ××™×•×©×")
    
    def clean_old_cache(self):
        """
        × ×™×§×•×™ ×§××© ×™×©×Ÿ
        """
        logger.info("ğŸ§¹ ×× ×§×” ×§××© ×™×©×Ÿ...")
        
        ttl_days = CACHE_CONFIG['daily_analysis_ttl_days']
        cutoff_date = datetime.now() - timedelta(days=ttl_days)
        
        try:
            # ××—×™×§×ª cache entries ×™×©× ×™×
            self.db_client.client.table('daily_analysis_cache')\
                .delete()\
                .lt('expires_at', cutoff_date.isoformat())\
                .execute()
            
            logger.info(f"âœ… × ×•×§×” ×§××© ×™×©×Ÿ ×-{cutoff_date.date()}")
        except Exception as e:
            logger.warning(f"âš ï¸ ×©×’×™××” ×‘× ×™×§×•×™ ×§××©: {e}")
    
    def run(self):
        """
        ×”×¨×¦×ª ×¢×“×›×•×Ÿ ×™×•××™ ××œ×
        """
        logger.info("ğŸš€ ××ª×—×™×œ ×¢×“×›×•×Ÿ ×™×•××™...")
        start_time = datetime.now()
        
        # 1. ×¢×“×›×•×Ÿ × ×ª×•× ×™ ×× ×™×•×ª
        stocks_from_db = self.db_client.get_stock_list(active_only=True)
        if not stocks_from_db:
            logger.error("âŒ ×œ× × ××¦××• ×× ×™×•×ª ×‘-DB! ×”×¨×¥ Apify scraper ×§×•×“×.")
            return
        
        symbols = [s['symbol'] for s in stocks_from_db]
        update_result = self.update_stock_data(symbols)
        
        # 2. ×—×™×©×•×‘ snapshots ×œ×™×•× ×”××—×¨×•×Ÿ
        snapshots_count = self.compute_today_snapshots()
        
        # 3. ×¢×“×›×•×Ÿ pattern statistics
        self.update_pattern_statistics()
        
        # 4. × ×™×§×•×™ ×§××© ×™×©×Ÿ
        self.clean_old_cache()
        
        elapsed = (datetime.now() - start_time).total_seconds()
        logger.info(f"âœ… ×¢×“×›×•×Ÿ ×™×•××™ ×”×•×©×œ× ×‘-{elapsed:.1f} ×©× ×™×•×ª")
        logger.info(f"   ğŸ“Š {snapshots_count} snapshots × ×•×¦×¨×•")
        logger.info(f"   ğŸ“¥ {update_result['updated']} ×× ×™×•×ª ×¢×•×“×›× ×•")


def main():
    """Main function"""
    engine = DailyUpdateEngine()
    engine.run()


if __name__ == '__main__':
    main()


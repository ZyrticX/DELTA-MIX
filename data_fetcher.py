"""
××•×“×•×œ ×”×•×¨×“×ª × ×ª×•× ×™× ×-Yahoo Finance
"""

import yfinance as yf
import pandas as pd
from datetime import datetime, timedelta
from typing import List, Dict
import time
import os
import pickle


class DataFetcher:
    """
    ××—×œ×§×” ×œ×”×•×¨×“×ª ×•×¢×“×›×•×Ÿ × ×ª×•× ×™ ×× ×™×•×ª
    """
    
    def __init__(self, cache_dir: str = "data_cache"):
        """
        ××ª×—×•×œ
        
        Args:
            cache_dir: ×ª×™×§×™×™×ª ×§××© ×œ×©××™×¨×ª × ×ª×•× ×™×
        """
        self.cache_dir = cache_dir
        os.makedirs(cache_dir, exist_ok=True)
        
    def get_sp500_symbols(self) -> List[str]:
        """
        ×§×‘×œ×ª ×¨×©×™××ª ×”×× ×™×•×ª ×©×œ S&P 500
        """
        # × ×™×¡×™×•×Ÿ 1: ×”×•×¨×“×” ××•×•×™×§×™×¤×“×™×” ×¢× requests
        try:
            import requests
            url = "https://en.wikipedia.org/wiki/List_of_S%26P_500_companies"
            
            # ×”×•×¡×¤×ª headers ×›×“×™ ×œ×”×™×× ×¢ ×-403
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            }
            
            # × ×™×¡×™×•×Ÿ ×¢× requests + pandas (×¢× timeout)
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                from io import StringIO
                tables = pd.read_html(StringIO(response.text))
                if tables and len(tables) > 0:
                    sp500_table = tables[0]
                    if 'Symbol' in sp500_table.columns:
                        symbols = sp500_table['Symbol'].tolist()
                        # × ×™×§×•×™ ×¡×™×× ×™× ××™×•×—×“×™×
                        symbols = [s.replace('.', '-') for s in symbols if pd.notna(s)]
                        if len(symbols) >= 400:  # ×‘×“×™×§×” ×©×™×© ×œ×¤×—×•×ª 400 ×× ×™×•×ª
                            print(f"âœ… × ××¦××• {len(symbols)} ×× ×™×•×ª ×‘-S&P 500 (××•×•×™×§×™×¤×“×™×”)")
                            return symbols
        except Exception as e:
            print(f"× ×™×¡×™×•×Ÿ 1 × ×›×©×œ: {e}")
        
        # × ×™×¡×™×•×Ÿ 2: pandas.read_html ×™×©×™×¨×•×ª
        try:
            url = "https://en.wikipedia.org/wiki/List_of_S%26P_500_companies"
            tables = pd.read_html(url, header=0, timeout=10)
            if tables and len(tables) > 0:
                sp500_table = tables[0]
                if 'Symbol' in sp500_table.columns:
                    symbols = sp500_table['Symbol'].tolist()
                    symbols = [s.replace('.', '-') for s in symbols if pd.notna(s)]
                    if len(symbols) >= 400:
                        print(f"âœ… × ××¦××• {len(symbols)} ×× ×™×•×ª ×‘-S&P 500 (××•×•×™×§×™×¤×“×™×” - ×©×™×˜×” 2)")
                        return symbols
        except Exception as e:
            print(f"× ×™×¡×™×•×Ÿ 2 × ×›×©×œ: {e}")
        
        # × ×™×¡×™×•×Ÿ 3: ×¨×©×™××” ××œ××” ×©×œ S&P 500 (×’×™×‘×•×™)
        print("âš ï¸ ×”×”×•×¨×“×” ××•×•×™×§×™×¤×“×™×” × ×›×©×œ×”, ××©×ª××© ×‘×¨×©×™××” ××œ××” ×©×œ S&P 500")
        return self._get_full_sp500_symbols()
    
    def load_symbols_from_file(self, filepath: str) -> List[str]:
        """
        ×˜×¢×™× ×ª ×¨×©×™××ª ×× ×™×•×ª ××§×•×‘×¥
        
        Args:
            filepath: × ×ª×™×‘ ×œ×§×•×‘×¥ (txt ××• csv ×¢× ×¢××•×“×” ××—×ª ×©×œ ×¡×™××•×œ×™×)
        
        Returns:
            ×¨×©×™××ª ×¡×™××•×œ×™×
        """
        try:
            if filepath.endswith('.csv'):
                df = pd.read_csv(filepath)
                # × ×¡×” ×¢××•×“×” ×¨××©×•× ×” ××• ×¢××•×“×” ×‘×©× 'Symbol'
                if 'Symbol' in df.columns:
                    symbols = df['Symbol'].tolist()
                else:
                    symbols = df.iloc[:, 0].tolist()
            else:
                # ×§×•×‘×¥ ×˜×§×¡×˜ - ×©×•×¨×” ××—×ª ×œ×›×œ ×¡×™××•×œ
                with open(filepath, 'r', encoding='utf-8') as f:
                    symbols = [line.strip() for line in f if line.strip()]
            
            # × ×™×§×•×™ ×¡×™×× ×™× ××™×•×—×“×™×
            symbols = [s.replace('.', '-') for s in symbols if s]
            print(f"× ×˜×¢× ×• {len(symbols)} ×× ×™×•×ª ××§×•×‘×¥: {filepath}")
            return symbols
        except Exception as e:
            print(f"×©×’×™××” ×‘×˜×¢×™× ×ª ×§×•×‘×¥ ×× ×™×•×ª: {e}")
            return []
    
    def _get_default_symbols(self) -> List[str]:
        """
        ×¨×©×™××ª ×‘×¨×™×¨×ª ××—×“×œ ×©×œ ×× ×™×•×ª (×œ××§×¨×” ×©×”×”×•×¨×“×” × ×›×©×œ×ª) - ×¨×©×™××” ×—×œ×§×™×ª
        """
        return [
            'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'TSLA', 'NVDA', 'JPM',
            'V', 'JNJ', 'WMT', 'PG', 'MA', 'HD', 'BAC', 'DIS', 'ADBE', 'NFLX',
            'CRM', 'CSCO', 'PEP', 'KO', 'INTC', 'AMD', 'PYPL', 'NKE', 'MRK',
            'TMO', 'ABBV', 'ABT', 'COST', 'ACN', 'AVGO', 'TXN', 'DHR', 'LLY',
            'UNP', 'NEE', 'PM', 'BMY', 'UPS', 'LOW', 'QCOM', 'HON', 'ORCL',
            'IBM', 'AMGN', 'GE', 'MDT', 'CAT', 'BA', 'MMM', 'GS', 'AXP'
        ]
    
    def _get_full_sp500_symbols(self) -> List[str]:
        """
        ×¨×©×™××” ××œ××” ×©×œ ×›×œ ×× ×™×•×ª S&P 500 (×’×™×‘×•×™ ×›×©×”×•×¨×“×” ××•×•×™×§×™×¤×“×™×” × ×›×©×œ×ª)
        ×¨×©×™××” ××¢×•×“×›× ×ª ×œ-2025 - ×›×œ 503 ×× ×™×•×ª S&P 500
        """
        # ×¨×©×™××” ××œ××” ×©×œ S&P 500 (××¢×•×“×›× ×ª 2025)
        # ××‘×•×¡×¡×ª ×¢×œ ×¨×©×™××” ×¨×©××™×ª ××¢×•×“×›× ×ª
        # ×¨×©×™××” ××œ××” ×©×œ S&P 500 - ××¢×•×“×›× ×ª ×œ×¤×™ ×”×¨×©×™××” ×”×—×“×©×”
        # ×›×œ 503 ×× ×™×•×ª ×œ×¤×™ ×”×¡×“×¨ ××”×¨×©×™××” ×”××¢×•×“×›× ×ª
        all_symbols = [
            'NVDA', 'AAPL', 'MSFT', 'AMZN', 'GOOGL', 'AVGO', 'GOOG', 'META', 'TSLA', 'BRK-B',
            'JPM', 'LLY', 'WMT', 'ORCL', 'V', 'MA', 'XOM', 'NFLX', 'JNJ', 'PLTR',
            'COST', 'BAC', 'ABBV', 'AMD', 'HD', 'PG', 'GE', 'CVX', 'KO', 'IBM',
            'UNH', 'CSCO', 'WFC', 'CAT', 'MU', 'MS', 'AXP', 'GS', 'PM', 'RTX',
            'CRM', 'TMUS', 'ABT', 'MCD', 'MRK', 'TMO', 'APP', 'LRCX', 'DIS', 'LIN',
            'PEP', 'ISRG', 'UBER', 'QCOM', 'AMAT', 'INTU', 'C', 'INTC', 'NOW', 'T',
            'SCHW', 'NEE', 'AMGN', 'VZ', 'APH', 'ANET', 'BLK', 'TJX', 'BKNG', 'KLAC',
            'GILD', 'ACN', 'BA', 'DHR', 'SPGI', 'GEV', 'BSX', 'TXN', 'ETN', 'PANW',
            'PFE', 'COF', 'ADBE', 'SYK', 'CRWD', 'LOW', 'UNP', 'WELL', 'DE', 'HON',
            'PGR', 'PLD', 'MDT', 'ADI', 'BX', 'HOOD', 'CB', 'KKR', 'LMT', 'HCA',
            'COP', 'VRTX', 'MCK', 'PH', 'CEG', 'ADP', 'SO', 'CMCSA', 'CVS', 'DELL',
            'CME', 'TT', 'MO', 'DUK', 'BMY', 'SBUX', 'GD', 'NKE', 'NEM', 'CDNS',
            'MMM', 'MMC', 'MCO', 'ICE', 'DASH', 'AMT', 'SHW', 'HWM', 'NOC', 'WM',
            'EQIX', 'ORLY', 'JCI', 'UPS', 'COIN', 'ABNB', 'MAR', 'BK', 'APO', 'CTAS',
            'GLW', 'EMR', 'MDLZ', 'SNPS', 'AON', 'USB', 'ECL', 'TDG', 'PNC', 'WMB',
            'TEL', 'ITW', 'COR', 'ELV', 'CI', 'RCL', 'REGN', 'MNST', 'DDOG', 'CSX',
            'PWR', 'MSI', 'AEP', 'GM', 'CMI', 'RSG', 'AJG', 'NSC', 'CL', 'ADSK',
            'TRV', 'HLT', 'PYPL', 'VST', 'FDX', 'SRE', 'FTNT', 'AZO', 'AFL', 'WDAY',
            'SPG', 'KMI', 'STX', 'EOG', 'DLR', 'APD', 'FCX', 'IDXX', 'MPC', 'TFC',
            'WBD', 'PSX', 'WDC', 'SLB', 'VLO', 'LHX', 'URI', 'ZTS', 'ROST', 'ALL',
            'PCAR', 'O', 'D', 'NXPI', 'F', 'BDX', 'MET', 'EA', 'NDAQ', 'AIG',
            'EW', 'PSA', 'XEL', 'ROP', 'CARR', 'BKR', 'FAST', 'CAH', 'AXON', 'EXC',
            'GWW', 'MPWR', 'AME', 'TTWO', 'CBRE', 'MSCI', 'ETR', 'OKE', 'CTVA', 'DHI',
            'LVS', 'AMP', 'KR', 'ROK', 'PEG', 'YUM', 'A', 'TGT', 'FANG', 'PAYX',
            'CMG', 'FICO', 'OXY', 'GRMN', 'CPRT', 'CCI', 'VMC', 'XYZ', 'DAL', 'PRU',
            'XYL', 'EBAY', 'TRGP', 'MLM', 'RMD', 'KDP', 'WEC', 'PCG', 'IQV', 'HIG',
            'ED', 'OTIS', 'VTR', 'SYY', 'CTSH', 'WAB', 'EQT', 'CCL', 'HSY', 'GEHC',
            'NUE', 'KMB', 'FIS', 'FI', 'STT', 'ACGL', 'NRG', 'KEYS', 'VICI', 'RJF',
            'LYV', 'EL', 'KVUE', 'MTD', 'EXPE', 'WTW', 'IBKR', 'IR', 'LEN', 'HPE',
            'UAL', 'MCHP', 'HUM', 'VRSK', 'IRM', 'EME', 'K', 'ODFL', 'CSGP', 'FSLR',
            'TER', 'CHTR', 'ROL', 'KHC', 'ATO', 'FITB', 'MTB', 'WRB', 'DTE', 'TSCO',
            'EXR', 'AEE', 'ADM', 'PPL', 'ES', 'SYF', 'CBOE', 'EXE', 'FE', 'BRO',
            'STE', 'CNP', 'AWK', 'BR', 'CINF', 'EFX', 'AVB', 'GIS', 'DOV', 'VLTO',
            'LDOS', 'HPQ', 'NTRS', 'HUBB', 'HBAN', 'TDY', 'SMCI', 'TPL', 'WSM', 'PHM',
            'HAL', 'BIIB', 'ULTA', 'JBL', 'TTD', 'PODD', 'DXCM', 'NTAP', 'STZ', 'EQR',
            'STLD', 'TROW', 'VRSN', 'WAT', 'CMS', 'CFG', 'EIX', 'PPG', 'RF', 'DG',
            'L', 'PTC', 'LH', 'SBAC', 'DLTR', 'CHD', 'DVN', 'DRI', 'INCY', 'TPR',
            'CTRA', 'NI', 'TYL', 'NVR', 'ON', 'WST', 'DGX', 'Q', 'CPAY', 'LULU',
            'RL', 'AMCR', 'KEY', 'IP', 'BG', 'TRMB', 'TSN', 'CDW', 'SW', 'J',
            'PFG', 'CNC', 'EXPD', 'GPN', 'GDDY', 'SNA', 'PKG', 'APTV', 'ZBH', 'CHRW',
            'PNR', 'GPC', 'MKC', 'LII', 'EVRG', 'LNT', 'INVH', 'BBY', 'HOLX', 'ESS',
            'WY', 'PSKY', 'DD', 'IT', 'FTV', 'LUV', 'IFF', 'JBHT', 'GEN', 'DOW',
            'MAA', 'TKO', 'ERIE', 'TXT', 'UHS', 'FFIV', 'ALLE', 'OMC', 'FOX', 'FOXA',
            'KIM', 'LYB', 'EG', 'DPZ', 'COO', 'AVY', 'CF', 'BALL', 'CLX', 'NDSN',
            'ZBRA', 'MAS', 'WYNN', 'BF-B', 'REG', 'IEX', 'BEN', 'DOC', 'HII', 'HRL',
            'HST', 'BLDR', 'JKHY', 'VTRS', 'DECK', 'SOLV', 'SJM', 'UDR', 'AKAM', 'BXP',
            'DAY', 'AIZ', 'HAS', 'ALB', 'GL', 'CPT', 'PNW', 'SWKS', 'SWK', 'IVZ',
            'RVTY', 'AES', 'ALGN', 'FDS', 'NWSA', 'MRNA', 'EPAM', 'PAYC', 'BAX', 'POOL',
            'ARE', 'IPG', 'AOS', 'TECH', 'CPB', 'GNRC', 'TAP', 'MGM', 'LW', 'DVA',
            'APA', 'CRL', 'NCLH', 'FRT', 'HSIC', 'CAG', 'MOS', 'MTCH', 'LKQ', 'MOH',
            'SOLS', 'MHK', 'NWS'
        ]
        
        # × ×™×§×•×™ ×›×¤×™×œ×•×™×•×ª ×•×©××™×¨×” ×¢×œ ×¡×“×¨
        seen = set()
        unique_symbols = []
        for symbol in all_symbols:
            if symbol not in seen:
                seen.add(symbol)
                unique_symbols.append(symbol)
        
        # × ×™×§×•×™ ×¡×™×× ×™× ××™×•×—×“×™×
        cleaned_symbols = [s.replace('.', '-') for s in unique_symbols if s]
        
        print(f"âœ… ×¨×©×™××” ××œ××” ×©×œ S&P 500: {len(cleaned_symbols)} ×× ×™×•×ª")
        return cleaned_symbols
    
    def download_stock_data(self, 
                          symbol: str,
                          start_date: str = "2012-01-01",
                          end_date: str = None,
                          use_cache: bool = True,
                          force_download: bool = False) -> pd.DataFrame:
        """
        ×”×•×¨×“×ª × ×ª×•× ×™ ×× ×™×” ×‘×•×“×“×ª
        
        Args:
            symbol: ×¡×™××•×œ ×”×× ×™×”
            start_date: ×ª××¨×™×š ×”×ª×—×œ×” (×‘×¨×™×¨×ª ××—×“×œ: 2012-01-01)
            end_date: ×ª××¨×™×š ×¡×™×•× (×‘×¨×™×¨×ª ××—×“×œ: ×”×™×•×)
            use_cache: ×”×× ×œ×”×©×ª××© ×‘×§××©
            force_download: ×”×× ×œ×›×¤×•×ª ×”×•×¨×“×” ××—×“×© (True = ×”×•×¨×“ ×‘×›×œ ××§×¨×”, False = ×”×©×ª××© ×‘×§××© ×× ×§×™×™×)
        """
        if end_date is None:
            end_date = datetime.now().strftime("%Y-%m-%d")
        
        cache_file = os.path.join(self.cache_dir, f"{symbol}_{start_date}_{end_date}.pkl")
        
        # ×‘×“×•×§ ×§××© - ×× ×œ× ×›×¤×™× ×• ×”×•×¨×“×” ×•×™×© ×§××©, ×ª××™×“ ×”×©×ª××© ×‘×•
        if use_cache and not force_download and os.path.exists(cache_file):
            try:
                with open(cache_file, 'rb') as f:
                    df = pickle.load(f)
                print(f"âœ… {symbol}: × ×˜×¢×Ÿ ××§××©")
                return df
            except Exception as e:
                print(f"âš ï¸ {symbol}: ×©×’×™××” ×‘×˜×¢×™× ×” ××§××© ({e}), ××•×¨×™×“ ××—×“×©...")
                # ×× × ×›×©×œ, × ×•×¨×™×“ ××—×“×©
        
        # ×”×•×¨×“×” ×-Yahoo Finance
        try:
            ticker = yf.Ticker(symbol)
            df = ticker.history(start=start_date, end=end_date)
            
            if df.empty:
                # ×‘×“×™×§×” ×× ×”×× ×™×” ×”×•×¡×¨×” ××”××¡×—×¨
                info = ticker.info
                if 'longName' not in info or info.get('quoteType') == 'DELISTED':
                    print(f"âš ï¸ {symbol}: ×× ×™×” ×”×•×¡×¨×” ××”××¡×—×¨ (delisted)")
                else:
                    print(f"âš ï¸ {symbol}: ××™×Ÿ × ×ª×•× ×™× ×–××™× ×™×")
                return None
            
            # ×‘×“×™×§×” ×©×™×© ×œ×¤×—×•×ª ×›××” ×©×•×¨×•×ª × ×ª×•× ×™×
            if len(df) < 10:
                print(f"âš ï¸ {symbol}: × ×ª×•× ×™× ××•×¢×˜×™× ××“×™ ({len(df)} ×™××™×)")
                return None
            
            # ×©××™×¨×” ×‘×§××©
            with open(cache_file, 'wb') as f:
                pickle.dump(df, f)
            
            return df
            
        except Exception as e:
            error_msg = str(e).lower()
            if 'delisted' in error_msg or 'no timezone' in error_msg or 'no price data' in error_msg:
                print(f"âš ï¸ {symbol}: ×× ×™×” ×”×•×¡×¨×” ××”××¡×—×¨ ××• ××™×Ÿ × ×ª×•× ×™×")
            else:
                print(f"âš ï¸ ×©×’×™××” ×‘×”×•×¨×“×ª {symbol}: {e}")
            return None
    
    def download_multiple_stocks(self,
                                symbols: List[str],
                                start_date: str = "2012-01-01",
                                end_date: str = None,
                                use_cache: bool = True,
                                force_download: bool = False,
                                max_workers: int = 10) -> pd.DataFrame:
        """
        ×”×•×¨×“×ª × ×ª×•× ×™× ×©×œ ××¡×¤×¨ ×× ×™×•×ª
        
        ××•×¨×™×“ ×-Yahoo Finance ××ª ×›×œ ×”× ×ª×•× ×™×, ××‘×œ ×©×•××¨ ×¨×§:
        - Close: ××—×™×¨ ×¡×’×™×¨×”
        - Adj Close: ××—×™×¨ ×¡×’×™×¨×” ××•×ª×× (××•×ª×× ×œ×¤×™×¦×•×œ×™ ×× ×™×•×ª ×•×“×™×‘×™×“× ×“×™×)
        - Volume: × ×¤×— ××¡×—×¨
        
        Args:
            force_download: ×× True, ×™×•×¨×™×“ ××—×“×© ×’× ×× ×™×© ×§××©. ×× False, ×™×©×ª××© ×‘×§××© ×× ×§×™×™×.
        
        Returns:
            DataFrame ×¢× MultiIndex: (symbol, field) - Close, Adj Close ×•-Volume
        """
        if end_date is None:
            end_date = datetime.now().strftime("%Y-%m-%d")
        
        print(f"××•×¨×™×“ × ×ª×•× ×™× ×¢×‘×•×¨ {len(symbols)} ×× ×™×•×ª...")
        print(f"×ª×§×•×¤×”: {start_date} ×¢×“ {end_date}")
        if use_cache and not force_download:
            print("ğŸ’¾ ××©×ª××© ×‘×§××© - ×œ× ×™×•×¨×™×“ × ×ª×•× ×™× ×©×›×‘×¨ ×§×™×™××™×")
        elif force_download:
            print("ğŸ”„ ×›×•×¤×” ×”×•×¨×“×” ××—×“×© - ××ª×¢×œ× ××§××©")
        
        all_data = {}
        failed_symbols = []
        
        for i, symbol in enumerate(symbols):
            if (i + 1) % 50 == 0:
                print(f"×”×ª×§×“××•×ª: {i+1}/{len(symbols)}")
            
            df = self.download_stock_data(symbol, start_date, end_date, use_cache, force_download)
            
            if df is not None and not df.empty:
                # ×‘×“×•×§ ××™×œ×• ×¢××•×“×•×ª ×–××™× ×•×ª
                available_columns = df.columns.tolist()
                
                # × ×¨××•×œ ×©××•×ª ×¢××•×“×•×ª (×”×¡×¨×ª ×¨×•×•×—×™× ××™×•×ª×¨×™×, ×”××¨×” ×œ-lowercase ×œ×‘×“×™×§×”)
                normalized_columns = {col.strip(): col for col in available_columns}
                normalized_lower = {col.strip().lower(): col for col in available_columns}
                
                # ××™×¤×•×™ ×©××•×ª ×¢××•×“×•×ª ××¤×©×¨×™×™× (yfinance ×™×›×•×œ ×œ×”×—×–×™×¨ ×©××•×ª ×©×•× ×™×)
                column_mapping = {
                    'Close': ['Close', 'close', 'CLOSE'],
                    'Adj Close': ['Adj Close', 'AdjClose', 'Adj_Close', 'adj close', 'ADJ CLOSE', 'AdjClose'],
                    'Volume': ['Volume', 'volume', 'VOLUME', 'vol']
                }
                
                # ×¤×•× ×§×¦×™×” ×¢×–×¨ ×œ××¦×™××ª ×¢××•×“×”
                def find_column(possible_names):
                    # × ×¡×” ××¦×™××ª ××“×•×™×§×ª
                    for col_name in possible_names:
                        if col_name in available_columns:
                            return col_name
                        # × ×¡×” ×¢× × ×¨××•×œ
                        if col_name.strip() in normalized_columns:
                            return normalized_columns[col_name.strip()]
                        # × ×¡×” case-insensitive
                        if col_name.strip().lower() in normalized_lower:
                            return normalized_lower[col_name.strip().lower()]
                    return None
                
                # ×‘×“×™×§×” ×¨××©×•× ×™×ª - ×× ××™×Ÿ Close, ×”×× ×™×” ×œ× ×ª×§×™× ×”
                close_col = find_column(column_mapping['Close'])
                close_found = close_col is not None
                
                if not close_found:
                    print(f"âš ï¸ {symbol}: ××™×Ÿ ×¢××•×“×ª 'Close' - ××“×œ×’ ×¢×œ ×× ×™×” ×–×•")
                    print(f"   ×¢××•×“×•×ª ×–××™× ×•×ª: {available_columns}")
                    failed_symbols.append(symbol)
                    continue
                
                # ×“×™×‘×•×’: ×”×“×¤×¡ ×¢××•×“×•×ª ×¢×‘×•×¨ ×× ×™×•×ª ×¨××©×•× ×•×ª (×œ××§×¨×” ×©×œ ×‘×¢×™×•×ª)
                if i < 3 and len(failed_symbols) == 0:
                    print(f"   {symbol}: ×¢××•×“×•×ª ×–××™× ×•×ª: {available_columns}")
                
                # ×©××•×¨ ×¨×§ ××ª ×”×©×“×•×ª ×”× ×“×¨×©×™× ×œ× ×™×ª×•×—:
                # - Close: ××—×™×¨ ×¡×’×™×¨×” (×œ×—×™×©×•×‘ ×§×•×¨×œ×¦×™×•×ª ××—×™×¨)
                # - Adj Close: ××—×™×¨ ×¡×’×™×¨×” ××•×ª×× (××•×ª×× ×œ×¤×™×¦×•×œ×™ ×× ×™×•×ª ×•×“×™×‘×™×“× ×“×™×)
                # - Volume: × ×¤×— ××¡×—×¨ (×œ×—×™×©×•×‘ ×§×•×¨×œ×¦×™×•×ª × ×¤×—)
                for field, possible_names in column_mapping.items():
                    found_column = find_column(possible_names)
                    
                    if found_column:
                        all_data[(symbol, field)] = df[found_column]
                    else:
                        # ×× ×œ× × ××¦××” ×”×¢××•×“×”, × ×“×¤×™×¡ ××–×”×¨×” ×•× ×©×ª××© ×‘×¢××•×“×” ×—×œ×•×¤×™×ª
                        if field == 'Adj Close':
                            # ×× ××™×Ÿ Adj Close, × ×©×ª××© ×‘-Close
                            if close_col:
                                if i < 5:  # ×”×“×¤×¡ ×¨×§ ×¢×‘×•×¨ 5 ×× ×™×•×ª ×¨××©×•× ×•×ª ×›×“×™ ×œ× ×œ×”×¦×™×£
                                    print(f"âš ï¸ {symbol}: ××™×Ÿ ×¢××•×“×ª 'Adj Close', ××©×ª××© ×‘-'Close'")
                                all_data[(symbol, field)] = df[close_col]
                            else:
                                # ×–×” ×œ× ×××•×¨ ×œ×§×¨×•×ª ×›×™ ×‘×“×§× ×• ×§×•×“×
                                failed_symbols.append(symbol)
                                break
                        elif field == 'Volume':
                            # Volume ×”×•× ××•×¤×¦×™×•× ×œ×™ ×™×•×ª×¨, × ×©×ª××© ×‘-0 ×× ××™×Ÿ
                            if i < 5:  # ×”×“×¤×¡ ×¨×§ ×¢×‘×•×¨ 5 ×× ×™×•×ª ×¨××©×•× ×•×ª
                                print(f"âš ï¸ {symbol}: ××™×Ÿ ×¢××•×“×ª 'Volume', ××©×ª××© ×‘-0")
                            all_data[(symbol, field)] = pd.Series(0, index=df.index)
            else:
                failed_symbols.append(symbol)
            
            # ×”×©×”×™×™×” ×§×œ×” ×›×“×™ ×œ× ×œ×”×¢××™×¡ ×¢×œ ×”×©×¨×ª
            if not use_cache:
                time.sleep(0.1)
        
        if failed_symbols:
            print(f"\nâš ï¸ × ×›×©×œ×• {len(failed_symbols)} ×× ×™×•×ª (×”×•×¡×¨×• ××”××¡×—×¨ ××• ××™×Ÿ × ×ª×•× ×™×)")
            if len(failed_symbols) <= 20:
                print(f"   ×× ×™×•×ª ×©× ×›×©×œ×•: {', '.join(failed_symbols)}")
            else:
                print(f"   ×× ×™×•×ª ×©× ×›×©×œ×• (20 ×¨××©×•× ×•×ª): {', '.join(failed_symbols[:20])}")
        
        # ×™×¦×™×¨×ª DataFrame ××—×“ ×’×“×•×œ
        combined_df = pd.DataFrame(all_data)
        
        if combined_df.empty:
            print("\nâŒ ×œ× ×”×•×¨×“×• × ×ª×•× ×™× ×¢×‘×•×¨ ××£ ×× ×™×”")
            return None
        
        successful_count = len(combined_df.columns) // 3  # Close, Adj Close, Volume
        print(f"\nâœ… ×”×•×©×œ××” ×”×•×¨×“×” ×©×œ {successful_count} ×× ×™×•×ª ××ª×•×š {len(symbols)}")
        print(f"   ×ª×§×•×¤×”: {combined_df.index.min()} ×¢×“ {combined_df.index.max()}")
        print(f"   ××¡×¤×¨ ×™××™×: {len(combined_df)}")
        
        return combined_df
    
    def update_daily(self, symbols: List[str]) -> pd.DataFrame:
        """
        ×¢×“×›×•×Ÿ ×™×•××™ - ××•×¨×™×“ ×¨×§ ××ª ×”× ×ª×•× ×™× ×”×—×“×©×™×
        """
        # ××¦× ××ª ×”×ª××¨×™×š ×”××—×¨×•×Ÿ ×‘×§××©
        latest_date = None
        
        for symbol in symbols[:5]:  # ×‘×“×•×§ 5 ×× ×™×•×ª ×¨××©×•× ×•×ª
            cache_files = [f for f in os.listdir(self.cache_dir) if f.startswith(symbol)]
            if cache_files:
                latest_file = max(cache_files, key=lambda f: os.path.getmtime(
                    os.path.join(self.cache_dir, f)
                ))
                file_date = datetime.fromtimestamp(
                    os.path.getmtime(os.path.join(self.cache_dir, latest_file))
                )
                if latest_date is None or file_date > latest_date:
                    latest_date = file_date
        
        if latest_date and latest_date.date() == datetime.now().date():
            print("×”× ×ª×•× ×™× ×›×‘×¨ ×¢×•×“×›× ×• ×”×™×•×")
            return None
        
        # ×”×•×¨×“ × ×ª×•× ×™× ×—×“×©×™×
        yesterday = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")
        today = datetime.now().strftime("%Y-%m-%d")
        
        print(f"××¢×“×›×Ÿ × ×ª×•× ×™× ×-{yesterday} ×¢×“ {today}")
        
        return self.download_multiple_stocks(
            symbols,
            start_date=yesterday,
            end_date=today,
            use_cache=False
        )
    
    def clear_cache(self):
        """
        × ×™×§×•×™ ×§××©
        """
        import shutil
        if os.path.exists(self.cache_dir):
            shutil.rmtree(self.cache_dir)
            os.makedirs(self.cache_dir)
        print("×§××© × ×•×§×”")


def test_fetcher():
    """
    ×‘×“×™×§×” ×‘×¡×™×¡×™×ª ×©×œ ××•×“×•×œ ×”×”×•×¨×“×”
    """
    fetcher = DataFetcher()
    
    # ×‘×“×™×§×” ×¢× ××¡×¤×¨ ×§×˜×Ÿ ×©×œ ×× ×™×•×ª
    test_symbols = ['AAPL', 'MSFT', 'GOOGL', 'TSLA', 'META']
    
    print("=== ×‘×“×™×§×ª ×”×•×¨×“×ª × ×ª×•× ×™× ===")
    data = fetcher.download_multiple_stocks(
        test_symbols,
        start_date="2023-01-01",
        end_date="2023-12-31"
    )
    
    print("\n=== ××™×“×¢ ×¢×œ ×”× ×ª×•× ×™× ===")
    print(f"×¦×•×¨×”: {data.shape}")
    print(f"×¢××•×“×•×ª: {data.columns.tolist()[:10]}")
    print(f"\n×“×•×’××”:")
    print(data.head())
    
    # ×‘×“×™×§×ª ×× ×™×™×ª ×™×™×—×•×¡
    print("\n=== ×‘×“×™×§×ª ×× ×™×™×ª ×™×™×—×•×¡ ===")
    ref_data = fetcher.get_reference_stock_data("SPY", "2023-01-01", "2023-12-31")
    print(f"××—×™×¨: {len(ref_data['price'])} ×™××™×")
    print(f"× ×¤×—: {len(ref_data['volume'])} ×™××™×")


if __name__ == '__main__':
    test_fetcher()
